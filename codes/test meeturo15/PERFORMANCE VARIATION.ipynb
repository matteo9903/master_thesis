{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f20598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "#import scikitplot as skplt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "from sklearn.utils.class_weight import compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916dfdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c04fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_DCR = pd.read_csv('data/classification/DCR/X_train.csv', index_col=0)\n",
    "X_t_DCR = pd.read_csv('data/classification/DCR/X_val.csv', index_col=0)\n",
    "y_tr_DCR = pd.read_csv('data/classification/DCR/y_train.csv', index_col=0)\n",
    "y_t_DCR = pd.read_csv('data/classification/DCR/y_val.csv', index_col=0)\n",
    "\n",
    "\n",
    "X_tr_OS = pd.read_csv('data/survival/OS/X_train.csv', index_col=0)\n",
    "X_t_OS = pd.read_csv('data/survival/OS/X_val.csv', index_col=0)\n",
    "y_tr_OS = pd.read_csv('data/survival/OS/y_train.csv', index_col=0)\n",
    "y_t_OS = pd.read_csv('data/survival/OS/y_val.csv', index_col=0)\n",
    "\n",
    "X_tr_PFS = pd.read_csv('data/survival/PFS/X_train.csv', index_col=0)\n",
    "X_t_PFS = pd.read_csv('data/survival/PFS/X_val.csv', index_col=0)\n",
    "y_tr_PFS = pd.read_csv('data/survival/PFS/y_train.csv', index_col=0)\n",
    "y_t_PFS = pd.read_csv('data/survival/PFS/y_val.csv', index_col=0)\n",
    "\n",
    "\n",
    "# values of the event must be boolean\n",
    "y_tr_OS['STATUS OS']=y_tr_OS['STATUS OS'].astype(bool)\n",
    "y_t_OS['STATUS OS']=y_t_OS['STATUS OS'].astype(bool)\n",
    "y_tr_PFS['STATUS PD']=y_tr_PFS['STATUS PD'].astype(bool)\n",
    "y_t_PFS['STATUS PD']=y_t_PFS['STATUS PD'].astype(bool)\n",
    "# targets must be an array (not a dataframe)\n",
    "y_tr_OS=y_tr_OS.to_records(index=False)\n",
    "y_t_OS=y_t_OS.to_records(index=False)\n",
    "y_tr_PFS=y_tr_PFS.to_records(index=False)\n",
    "y_t_PFS=y_t_PFS.to_records(index=False)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ef75c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_train = compute_sample_weight(class_weight='balanced', y=y_tr_DCR)\n",
    "sw_test = compute_sample_weight(class_weight='balanced', y=y_t_DCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5e13a6",
   "metadata": {},
   "source": [
    "# DCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fa486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import best classification model\n",
    "path = 'results/classification/DCR/RFE/MODELS/RF.pkl'\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4e8a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = pickle.load(open(path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b0215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = mod.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40609507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLINICAL FEATURES TO REMOVE\n",
    "drop_clin = ['Bone metastases', 'logNLR', 'Heng Score at baseline']  # RF - RFE\n",
    "\n",
    "# TOP 3 SHAP FEATURES\n",
    "drop_shap = ['logPLR', 'logSII',\"logEosinophils\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3f190",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_tr_DCR.copy()\n",
    "X_test = X_t_DCR.copy()\n",
    "\n",
    "feats = mod.feature_names_in_\n",
    "\n",
    "#   with LGBM\n",
    "#feats = mod.feature_name_\n",
    "#feats = [feats[i].replace('_',' ') for i in range(len(feats))]\n",
    "\n",
    "X_train = X_train.loc[:,feats]\n",
    "X_test = X_test.loc[:,feats]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526de133",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {'max_depth': [2], 'min_samples_leaf': [4], 'min_samples_split': [2], 'n_estimators': [50]}\n",
    "]\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "models = [ ]\n",
    "\n",
    "X_tr = [\n",
    "    X_train,\n",
    "    X_train.copy().drop(drop_shap, axis = 1),\n",
    "    X_train.copy().drop(drop_clin, axis = 1)\n",
    "]\n",
    "\n",
    "X_t = [\n",
    "    X_test,\n",
    "    X_test.copy().drop(drop_shap, axis = 1),\n",
    "    X_test.copy().drop(drop_clin, axis = 1)\n",
    "]\n",
    "\n",
    "y_train = y_tr_DCR.copy()\n",
    "y_test = y_t_DCR.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668c58d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statistics \n",
    "\n",
    "F1_train = []\n",
    "F1_test = []\n",
    "fit_params = {'sample_weight': sw_train}\n",
    "\n",
    "f1_tr = []\n",
    "f1_t = []\n",
    "\n",
    "# AVERAGE 10 TIMES THE MODEL WITH SELECTED FEATURES\n",
    "for i in range(10):\n",
    "    gs1 = GridSearchCV(model,params,cv=cv,return_train_score=True, n_jobs=-1)\n",
    "    gs1.fit(X_tr[0], y_train, **fit_params)\n",
    "    new_m1 = gs1.best_estimator_\n",
    "    new_m1.fit(X_tr[0], y_train,**fit_params)\n",
    "    \n",
    "    f1_tr.append(f1_score(y_train, new_m1.predict(X_tr[0]), average=\"weighted\", sample_weight=sw_train))\n",
    "    f1_t.append(f1_score(y_test, new_m1.predict(X_t[0]), average=\"weighted\", sample_weight=sw_test))\n",
    "    \n",
    "\n",
    "F1_train.append(statistics.mean(f1_tr))\n",
    "F1_test.append(statistics.mean(f1_t))\n",
    "\n",
    "models.append(new_m1)\n",
    "\n",
    "\n",
    "f1_tr = []\n",
    "f1_t = []\n",
    "\n",
    "del gs1\n",
    "# AVERAGE 10 TIMES THE MODEL WITHOUT SHAP FEATURES\n",
    "for i in range(10):\n",
    "    gs1 = GridSearchCV(model,params,cv=cv,return_train_score=True, n_jobs=-1)\n",
    "    gs1.fit(X_tr[1], y_train, **fit_params)\n",
    "    new_m1 = gs1.best_estimator_\n",
    "    new_m1.fit(X_tr[1], y_train,**fit_params)\n",
    "    \n",
    "    f1_tr.append(f1_score(y_train, new_m1.predict(X_tr[1]), average=\"weighted\", sample_weight=sw_train))\n",
    "    f1_t.append(f1_score(y_test, new_m1.predict(X_t[1]), average=\"weighted\", sample_weight=sw_test))\n",
    "    \n",
    "\n",
    "F1_train.append(statistics.mean(f1_tr))\n",
    "F1_test.append(statistics.mean(f1_t))\n",
    "\n",
    "models.append(new_m1)\n",
    "\n",
    "\n",
    "f1_tr = []\n",
    "f1_t = []\n",
    "\n",
    "del gs1\n",
    "# AVERAGE 10 TIMES THE MODEL WITHOUT CLINICAL FEATURES\n",
    "for i in range(10):\n",
    "    gs1 = GridSearchCV(model,params,cv=cv,return_train_score=True, n_jobs=-1)\n",
    "    gs1.fit(X_tr[2], y_train, **fit_params)\n",
    "    new_m1 = gs1.best_estimator_\n",
    "    new_m1.fit(X_tr[2], y_train,**fit_params)\n",
    "    \n",
    "    f1_tr.append(f1_score(y_train, new_m1.predict(X_tr[2]), average=\"weighted\", sample_weight=sw_train))\n",
    "    f1_t.append(f1_score(y_test, new_m1.predict(X_t[2]), average=\"weighted\", sample_weight=sw_test))\n",
    "    \n",
    "\n",
    "F1_train.append(statistics.mean(f1_tr))\n",
    "F1_test.append(statistics.mean(f1_t))\n",
    "\n",
    "\n",
    "models.append(new_m1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b1651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F1_train)\n",
    "print(F1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf325b1d",
   "metadata": {},
   "source": [
    "### BOOTSTRAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f869ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 1000\n",
    "import random, math\n",
    "results = []\n",
    "\n",
    "for i in range(0,3):\n",
    "    result = []\n",
    "    for j in range(n_iter):\n",
    "        x = [random.randint(0,X_t[i].shape[0]-1) for k in range(0,math.floor(X_t[i].shape[0]/2))]\n",
    "        test = X_t[i].copy()\n",
    "        test = test.iloc[x,:]\n",
    "        y_t_bs = y_test.copy()\n",
    "        y_t_bs = y_t_bs.iloc[x,:]\n",
    "        sw_x = compute_sample_weight(class_weight='balanced', y=y_t_bs)\n",
    "        res = f1_score(y_t_bs, models[i].predict(test), average=\"weighted\", sample_weight=sw_x)\n",
    "        result.append(res)\n",
    "\n",
    "    result.sort()\n",
    "    results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09b94e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence intervals\n",
    "alpha = 0.95\n",
    "p_low = ((1.0-alpha)/2.0) * 100\n",
    "p_high = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "\n",
    "for i in range(0,3):\n",
    "    lower = max(0.0, np.percentile(results[i], p_low))\n",
    "    upper = min(1.0, np.percentile(results[i], p_high))\n",
    "    print('%.0f%% confidence interval %.3f and %.3f' % (alpha*100, lower, upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc07b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb3c3804",
   "metadata": {},
   "source": [
    "# OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a983c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored, cumulative_dynamic_auc, concordance_index_ipcw, integrated_brier_score\n",
    "from sksurv.ensemble import RandomSurvivalForest, ExtraSurvivalTrees\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "from sksurv.svm import FastKernelSurvivalSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0438468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'results/survival/OS/MODELS(ALL)/EST.pkl'  # EST-ALL\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = pickle.load(open(path, 'rb'))\n",
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436f6149",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = mod.feature_names_in_\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a85a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_tr_OS.copy()\n",
    "X_test = X_t_OS.copy()\n",
    "\n",
    "X_train = X_train.loc[:,feats]\n",
    "X_test = X_test.loc[:,feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eccbc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_clin = ['Bone metastases', 'logNLR', 'Heng Score at baseline']\n",
    "\n",
    "drop_shap = ['KPS',\"Surgery\", 'logPLR']  \n",
    "models=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470b9532",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': [3], 'min_samples_leaf': [3], 'min_samples_split': [3], 'n_estimators': [100]}\n",
    "\n",
    "model = ExtraSurvivalTrees()\n",
    "\n",
    "X_tr = [\n",
    "    X_train,\n",
    "    X_train.copy().drop(drop_shap, axis = 1),\n",
    "    X_train.copy().drop(drop_clin, axis = 1)\n",
    "]\n",
    "\n",
    "X_t = [\n",
    "    X_test,\n",
    "    X_test.copy().drop(drop_shap, axis = 1),\n",
    "    X_test.copy().drop(drop_clin, axis = 1)\n",
    "]\n",
    "\n",
    "y_tr = y_tr_OS.copy()\n",
    "y_t = y_t_OS.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e337ae11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "ci_train=[ ]\n",
    "ci_test=[  ]\n",
    "\n",
    "\n",
    "CIT = []\n",
    "CITR = []\n",
    "\n",
    "for i in range(10):\n",
    "    gs1 = GridSearchCV(model,params,cv=cv,return_train_score=True, n_jobs=-1)\n",
    "    gs1.fit(X_tr[0], y_tr)\n",
    "    new_m1 = gs1.best_estimator_\n",
    "    ci_tr = concordance_index_censored(y_tr[\"STATUS OS\"], y_tr[\"OS\"], new_m1.predict(X_tr[0]))\n",
    "    ci_t = concordance_index_censored(y_t[\"STATUS OS\"], y_t[\"OS\"], new_m1.predict(X_t[0]))\n",
    "    CITR.append(ci_tr[0])\n",
    "    CIT.append(ci_t[0])\n",
    "\n",
    "ci_train.append(statistics.mean(CITR))\n",
    "ci_test.append(statistics.mean(CIT))\n",
    "\n",
    "models.append(new_m1)\n",
    "\n",
    "CIT = []\n",
    "CITR = []\n",
    "\n",
    "for i in range(10):\n",
    "    gs1 = GridSearchCV(model,params,cv=cv,return_train_score=True, n_jobs=-1)\n",
    "    gs1.fit(X_tr[1], y_tr)\n",
    "    new_m1 = gs1.best_estimator_\n",
    "    ci_tr = concordance_index_censored(y_tr[\"STATUS OS\"], y_tr[\"OS\"], new_m1.predict(X_tr[1]))\n",
    "    ci_t = concordance_index_censored(y_t[\"STATUS OS\"], y_t[\"OS\"], new_m1.predict(X_t[1]))\n",
    "    CITR.append(ci_tr[0])\n",
    "    CIT.append(ci_t[0])\n",
    "\n",
    "ci_train.append(statistics.mean(CITR))\n",
    "ci_test.append(statistics.mean(CIT))\n",
    "    \n",
    "models.append(new_m1)\n",
    "\n",
    "CIT = []\n",
    "CITR = []\n",
    "\n",
    "del gs1\n",
    "\n",
    "for i in range(10):\n",
    "    gs1 = GridSearchCV(model,params,cv=cv,return_train_score=True, n_jobs=-1)\n",
    "    gs1.fit(X_tr[2], y_tr)\n",
    "    new_m1 = gs1.best_estimator_\n",
    "    ci_tr = concordance_index_censored(y_tr[\"STATUS OS\"], y_tr[\"OS\"], new_m1.predict(X_tr[2]))\n",
    "    ci_t = concordance_index_censored(y_t[\"STATUS OS\"], y_t[\"OS\"], new_m1.predict(X_t[2]))\n",
    "    CITR.append(ci_tr[0])\n",
    "    CIT.append(ci_t[0])\n",
    "\n",
    "ci_train.append(statistics.mean(CITR))\n",
    "ci_test.append(statistics.mean(CIT))\n",
    "\n",
    "models.append(new_m1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f0e20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ci_train)\n",
    "print(ci_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40748112",
   "metadata": {},
   "source": [
    "### BOOTSTRAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b28ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 1000\n",
    "import random, math\n",
    "results = []\n",
    "\n",
    "for i in range(0,3):\n",
    "    result = []\n",
    "    for j in range(n_iter):\n",
    "        x = [random.randint(0,X_t[i].shape[0]-1) for k in range(0,math.floor(X_t[i].shape[0]/2))]\n",
    "        test = X_t[i].copy()\n",
    "        test = test.iloc[x,:]\n",
    "        y_t_bs = y_t.copy()\n",
    "        y_t_bs = y_t_bs[x]\n",
    "        res = concordance_index_censored(y_t_bs[\"STATUS OS\"], y_t_bs[\"OS\"], models[i].predict(test))\n",
    "        result.append(res[0])\n",
    "\n",
    "    result.sort()\n",
    "    results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1839de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence intervals\n",
    "alpha = 0.95\n",
    "p_low = ((1.0-alpha)/2.0) * 100\n",
    "p_high = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "\n",
    "for i in range(0,3):\n",
    "    lower = max(0.0, np.percentile(results[i], p_low))\n",
    "    upper = min(1.0, np.percentile(results[i], p_high))\n",
    "    print('%.0f%% confidence interval %.3f and %.3f' % (alpha*100, lower, upper))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1773073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "003c9a09",
   "metadata": {},
   "source": [
    "# PFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662ea503",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'results/survival/PFS/MODELS(ALL)/GB.pkl'\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ad83cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = pickle.load(open(path, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a203af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = mod.feature_names_in_\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2158af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_tr_PFS.copy()\n",
    "X_test = X_t_PFS.copy()\n",
    "\n",
    "X_train = X_train.loc[:,feats]\n",
    "X_test = X_test.loc[:,feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc61458",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_clin = ['Bone metastases', 'logNLR', 'Heng Score at baseline']  \n",
    "\n",
    "drop_shap =  ['KPS',\"logEosinophils\", 'logPLR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c61a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'learning_rate': [0.1], 'max_depth': [2], 'min_samples_leaf': [4], 'min_samples_split': [3]}\n",
    "\n",
    "\n",
    "model = GradientBoostingSurvivalAnalysis()\n",
    "\n",
    "\n",
    "models = []\n",
    "\n",
    "X_tr = [\n",
    "    X_train,\n",
    "    X_train.copy().drop(drop_shap, axis = 1),\n",
    "    X_train.copy().drop(drop_clin, axis = 1)\n",
    "]\n",
    "\n",
    "X_t = [\n",
    "    X_test,\n",
    "    X_test.copy().drop(drop_shap, axis = 1),\n",
    "    X_test.copy().drop(drop_clin, axis = 1)\n",
    "]\n",
    "\n",
    "y_tr = y_tr_PFS.copy()\n",
    "y_t = y_t_PFS.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b766f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "ci_train=[ ]\n",
    "ci_test=[  ]\n",
    "\n",
    "\n",
    "CIT = []\n",
    "CITR = []\n",
    "\n",
    "for i in range(10):\n",
    "    gs1 = GridSearchCV(model,params,cv=cv,return_train_score=True, n_jobs=-1)\n",
    "    gs1.fit(X_tr[0], y_tr)\n",
    "    new_m1 = gs1.best_estimator_\n",
    "    ci_tr = concordance_index_censored(y_tr[\"STATUS PD\"], y_tr[\"PFS\"], new_m1.predict(X_tr[0]))\n",
    "    ci_t = concordance_index_censored(y_t[\"STATUS PD\"], y_t[\"PFS\"], new_m1.predict(X_t[0]))\n",
    "    CITR.append(ci_tr[0])\n",
    "    CIT.append(ci_t[0])\n",
    "\n",
    "ci_train.append(statistics.mean(CITR))\n",
    "ci_test.append(statistics.mean(CIT))\n",
    "\n",
    "models.append(new_m1)\n",
    "\n",
    "CIT = []\n",
    "CITR = []\n",
    "\n",
    "for i in range(10):\n",
    "    gs1 = GridSearchCV(model,params,cv=cv,return_train_score=True, n_jobs=-1)\n",
    "    gs1.fit(X_tr[1], y_tr)\n",
    "    new_m1 = gs1.best_estimator_\n",
    "    ci_tr = concordance_index_censored(y_tr[\"STATUS PD\"], y_tr[\"PFS\"], new_m1.predict(X_tr[1]))\n",
    "    ci_t = concordance_index_censored(y_t[\"STATUS PD\"], y_t[\"PFS\"], new_m1.predict(X_t[1]))\n",
    "    CITR.append(ci_tr[0])\n",
    "    CIT.append(ci_t[0])\n",
    "\n",
    "ci_train.append(statistics.mean(CITR))\n",
    "ci_test.append(statistics.mean(CIT))\n",
    "    \n",
    "models.append(new_m1)\n",
    "\n",
    "CIT = []\n",
    "CITR = []\n",
    "\n",
    "del gs1\n",
    "\n",
    "for i in range(10):\n",
    "    gs1 = GridSearchCV(model,params,cv=cv,return_train_score=True, n_jobs=-1)\n",
    "    gs1.fit(X_tr[2], y_tr)\n",
    "    new_m1 = gs1.best_estimator_\n",
    "    ci_tr = concordance_index_censored(y_tr[\"STATUS PD\"], y_tr[\"PFS\"], new_m1.predict(X_tr[2]))\n",
    "    ci_t = concordance_index_censored(y_t[\"STATUS PD\"], y_t[\"PFS\"], new_m1.predict(X_t[2]))\n",
    "    CITR.append(ci_tr[0])\n",
    "    CIT.append(ci_t[0])\n",
    "\n",
    "ci_train.append(statistics.mean(CITR))\n",
    "ci_test.append(statistics.mean(CIT))\n",
    "\n",
    "models.append(new_m1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4e5651",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ci_train)\n",
    "print(ci_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca0b6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a7c93d6",
   "metadata": {},
   "source": [
    "### BOOTSTRAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8006401",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 1000\n",
    "import random, math\n",
    "results = []\n",
    "\n",
    "for i in range(0,3):\n",
    "    result = []\n",
    "    for j in range(n_iter):\n",
    "        x = [random.randint(0,X_t[i].shape[0]-1) for k in range(0,math.floor(X_t[i].shape[0]/2))]\n",
    "        test = X_t[i].copy()\n",
    "        test = test.iloc[x,:]\n",
    "        y_t_bs = y_t.copy()\n",
    "        y_t_bs = y_t_bs[x]\n",
    "        res = concordance_index_censored(y_t_bs[\"STATUS PD\"], y_t_bs[\"PFS\"], models[i].predict(test))\n",
    "        result.append(res[0])\n",
    "\n",
    "    result.sort()\n",
    "    results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58660b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence intervals\n",
    "alpha = 0.95\n",
    "p_low = ((1.0-alpha)/2.0) * 100\n",
    "p_high = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "\n",
    "for i in range(0,3):\n",
    "    lower = max(0.0, np.percentile(results[i], p_low))\n",
    "    upper = min(1.0, np.percentile(results[i], p_high))\n",
    "    print('%.0f%% confidence interval %.3f and %.3f' % (alpha*100, lower, upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5341b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6057e5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
