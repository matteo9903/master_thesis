{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a02ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "from sklearn.utils.class_weight import compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5dc7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f82d693",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/classification/DCR/X_train.csv', index_col=0)\n",
    "X_test = pd.read_csv('data/classification/DCR/X_val.csv', index_col=0)\n",
    "y_train = pd.read_csv('data/classification/DCR/y_train.csv', index_col=0)\n",
    "y_test = pd.read_csv('data/classification/DCR/y_val.csv', index_col=0)\n",
    "\n",
    "y_train=y_train.squeeze()\n",
    "y_test=y_test.squeeze()\n",
    "\n",
    "\n",
    "# 10 folds stratified cross-validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7665ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions to fit the models and print scores\n",
    "from ipynb.fs.full.functions import fit_model, fit_model_MLP, print_report, print_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fbeb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['XGB', 'LR', 'RF', 'MLP','SVM','AB','ET','LGBM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d746f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "          XGBClassifier(),\n",
    "          LogisticRegression(), \n",
    "          RandomForestClassifier(),\n",
    "          MLPClassifier(),\n",
    "          SVC(probability = True),\n",
    "          AdaBoostClassifier(),\n",
    "          ExtraTreesClassifier(),\n",
    "          LGBMClassifier()\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4cd9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT THE SELECTED FEATURES BY EACH METHOD\n",
    "selMRMR = pd.read_csv('MRMRfeats.csv', index_col=0).transpose()\n",
    "selected_features_MRMR = [list(selMRMR.iloc[:,i].dropna()) for i in range(selMRMR.shape[1])]\n",
    "\n",
    "selFFS = pd.read_csv('FFSfeats.csv', index_col=0).transpose()\n",
    "selected_features_FFS = [list(selFFS.iloc[:,i].dropna()) for i in range(selFFS.shape[1])]\n",
    "\n",
    "selBFS = pd.read_csv('BFSfeats.csv', index_col=0).transpose()\n",
    "selected_features_BFS = [list(selBFS.iloc[:,i].dropna()) for i in range(selBFS.shape[1])]\n",
    "\n",
    "selRFE = pd.read_csv('RFEfeats.csv', index_col=0).transpose()\n",
    "selected_features_RFE = [list(selRFE.iloc[:,i].dropna()) for i in range(selRFE.shape[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b12cd",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb0a54f",
   "metadata": {},
   "source": [
    "## CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f093064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample weights for training and test set\n",
    "sw_train = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "sw_test = compute_sample_weight(class_weight='balanced', y=y_test)\n",
    "\n",
    "# set the classification outcome\n",
    "outcome = 'DCR'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313c7ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this variable according to the feature selector you want to compute the scores\n",
    "selection = 'RFE'\n",
    "\n",
    "# vector for setting the path to which save the results\n",
    "path_params = [outcome, selection]\n",
    "path_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa637d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of hyperparameters for model tuning, you can add all the parameters you want and also change the values of them \n",
    "# that you want to test\n",
    "\n",
    "parameters = [\n",
    "    {'max_depth':[2,3],'eta':[0.01,0.03,0.3], 'n_estimators': [30,50,100], 'lambda':[1,3,8]},\n",
    "    {\"C\":[1e-4,1e-3,1e-2,0.1,1,10]},\n",
    "    {'max_depth' : [2,3],'min_samples_leaf' : [2,3,4], 'min_samples_split': [2,3,4], 'n_estimators':[50,100]},\n",
    "    {\"hidden_layer_sizes\":[10], \"alpha\": [0.001,0.01,0.1,1], 'max_iter':[2000]},\n",
    "    {\"C\":[1e-3,0.01,0.1,1], 'kernel':['rbf','linear'], 'gamma':[0.01,0.1,1, 10, 100]},\n",
    "    {'learning_rate' : [0.001,0.01, 0.1],'base_estimator': [ DecisionTreeClassifier(max_depth=i) for i in range(2,4) ], 'n_estimators':[30,50,100]},\n",
    "    {'max_depth' : [2,3],'min_samples_leaf' : [3,4,5], 'min_samples_split': [2,3,4], 'n_estimators':[50,100]},\n",
    "    {'learning_rate' : [0.001, 0.01, 0.1,1], 'max_depth':[2,3],'num_leaves':[5,10,20,31],'n_estimators': [30,50,100]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efdab99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT THIS LINE AND COMMENT THE OTHER IF YOU WANT TO TRAIN WITH ALL THE FEATURES\n",
    "#X_tr = X_train.copy()\n",
    "#X_t = X_test.copy()\n",
    "\n",
    "# change the vector of selected features in function of the selector\n",
    "# change the index number in function of the model you want to train (look to the variable \"classifiers\")\n",
    "X_tr = X_train.loc[:, selected_features_RFE[0]]\n",
    "X_t = X_test.loc[:, selected_features_RFE[0]]\n",
    "\n",
    "print(X_tr.shape)\n",
    "scores = fit_model(classifiers[0],parameters[0], X_tr, y_train, X_t, y_test, sw_train, sw_test)\n",
    "# fitMLP is another function because MLP doesn't have sample weights\n",
    "# scores = fit_modelMLP(classifiers[3],parameters[3], X_tr, y_train, X_t, y_test, sw_train, sw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833f75c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print F1, accuracy and hyperparamters selected by gridsearch\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e84e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print classification report, confusion matrix and ROC curve\n",
    "print_report(scores[7], scores[6], 'XGB', X_t, y_test, sw_test, path_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1103875",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save the trained model with pickle, in order to be further tested on other data\n",
    "import pickle\n",
    "path = 'results/classification/DCR/{fs}/MODELS/{n}.pkl'.format(fs=selection, n=names[0])\n",
    "pickle.dump(scores[7], open(path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba74d533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9046ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
